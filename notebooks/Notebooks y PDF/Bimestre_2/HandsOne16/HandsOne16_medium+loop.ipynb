{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a8d4ec5-2584-49be-ad23-2348547e584b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listo\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = 'gpt2-medium'  # You can start with 'gpt2' (medium) and then experiment with larger models\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "print(\"listo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f702b32-d80e-4887-aaa3-7be5a9e57b66",
   "metadata": {},
   "source": [
    "### definir la función generate creative content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0324a21-5dfa-4ba1-b245-a449cf6d2b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  The cats are pretty good pets for kids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: , but they're not very friendly. They'll bark at you if you try to pet them or run away from your hand when it's time.\"\n",
      "\"I'm sorry,\" I said as my eyes fell on the cat sitting in front of me. \"It looks like a dog!\" The kitten was staring up into its owner with wide-eyed curiosity. It looked so cute! And then there were those big ears and tail that made him look even more adorable than he already did. He had long black hair hanging down his back which seemed almost too short by comparison. His face wasn't quite round enough yet either; instead, we could see some wrinkles around his mouth and nose. But what really caught our attention was how much bigger this guy was compared against us: about three times taller (and probably twice heavier) than any other kitty alive today. We couldn´t help but notice all these differences between each one… especially since none would have been noticed without looking closely through their fur. This is why people often call animals 'furballs'. In fact most humans don`nt know exactly where an animal comes out of until after seeing something strange happen – such things can be hard sometimes because no matter who sees someone else being weirded off before anything happens, nobody will ever believe anyone has seen another person doing crazy stuff just moments before…. except maybe yourself? Well now everyone knows anyway!!\n",
      "\n",
      "    <!--iframe-->   //\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  give me an example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  --> <div class=\"sw--display table tony_small ------------olive sw1\"><a href=\"#\">Tiny</A></span> TONY<br />LOOK AT THIS KITTEN!!! IT'S SO BIG AND HE IS NOT A CAT!!!!!!!!! </p><p class=3D\"MsoNormal\"></P>\"\n"
     ]
    }
   ],
   "source": [
    "def generate_creative_content(prompt, context=None, max_length=500, temperature=10.0, repetition_penalty=1.2, no_repeat_ngram_size=3):\n",
    "    \"\"\"Generate creative content using GPT-2 based on a given prompt and context.\"\"\"\n",
    "    \n",
    "    # Combine prompt and context if available\n",
    "    if context is not None:\n",
    "        prompt = context + \" \" + prompt\n",
    "\n",
    "    # Encode the prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate text\n",
    "    # Generate text with repetition penalty and no repeat n-grams\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode and return the generated text\n",
    "    generated_text = tokenizer.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# definimos la variable que almacenará el contexto\n",
    "context = None\n",
    "\n",
    "\n",
    "# Generamos el bucle que mantiene vivo el contexto de los prompts\n",
    "while True:\n",
    "    prompt = input(\"You: \")\n",
    "    if prompt.lower() == \"exit\":\n",
    "        break\n",
    "    \n",
    "    generated_text = generate_creative_content(prompt, context=context)\n",
    "    \n",
    "    # Aquí actializamos el contexto\n",
    "    context = generated_text\n",
    "    \n",
    "    print(\"AI:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c6a5a-b091-430a-bc34-7d030f1a0da6",
   "metadata": {},
   "source": [
    "### Usar varios promps para probar la capacidad creativa de GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411911ad-cf4f-49d5-90d4-eb06edb93577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: flat earth\n",
      ".\n",
      "\n",
      "The earth is flat because it is flat.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth is round because it is round.\n",
      "\n",
      "The earth\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: Once upon a time, in a kingdom far away,\n",
      " there lived a king who was a great warrior. He was a great warrior, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: In a dystopian future, where AI rules the world,\n",
      " the only way to survive is to become a cyborg.\n",
      "\n",
      "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
      "\n",
      "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
      "\n",
      "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
      "\n",
      "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
      "\n",
      "The game is set in a dystopian future where\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: The last dinosaur on Earth was not like the others. It\n",
      " was a giant, bipedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadruped\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: Deep beneath the ocean waves, a secret civilization\n",
      " has been building a vast network of underground tunnels. The tunnels are filled with powerful weapons and technology, and are guarded by powerful creatures.\n",
      "\n",
      "The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the year 2277, and the player is a member of the Brotherhood of Steel. The player is tasked with finding a way to infiltrate the Brotherhood's underground network, and to stop the Brotherhood from destroying the world.\n",
      "\n",
      "The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the year 2277, and the player is a member of the Brotherhood of Steel.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"flat earth\",\n",
    "    \"Once upon a time, in a kingdom far away,\",\n",
    "    \"In a dystopian future, where AI rules the world,\",\n",
    "    \"The last dinosaur on Earth was not like the others. It\",\n",
    "    \"Deep beneath the ocean waves, a secret civilization\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(generate_creative_content(prompt))\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45273b57-e89a-495d-917a-a1d9b1ddae64",
   "metadata": {},
   "source": [
    "### Puedo concluir que el texto generado es mucho mas fiable mientras el modelo sea mas largo en su entrenamiento asi como la presición de las respuestas al cambiarle temperature y la longitud de los tokens para generar mas promps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81678fff-b1f8-4919-b854-8531e501cec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
